{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q keras-nlp --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras_nlp\n",
    "import keras\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "label_names = [\"entailment\", \"neutral\", \"contradiction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/contradictory-my-dear-watson/'\n",
    "for dirname, _, filenames in os.walk(DATA_DIR):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_labels(x, y):\n",
    "    return (x[0], x[1]), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 28\n",
    "buffer_size = batch_size * 10\n",
    "\n",
    "training_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            df_train[[\"hypothesis\", \"premise\"]].values,\n",
    "            df_train[\"label\"].values\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Size of the train dataset: {len(training_dataset)}\")\n",
    "\n",
    "train_preprocessed = training_dataset.shuffle(buffer_size=buffer_size).map(split_labels, tf.data.AUTOTUNE).batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_discriminator_token = keras_nlp.models.Tokenizer.from_preset(\"electra_small_discriminator_uncased_en\")\n",
    "bert_preprocessor = keras_nlp.models.BertTextClassifierPreprocessor(electra_discriminator_token, sequence_length=240)\n",
    "\n",
    "train_set = (\n",
    "    train_preprocessed.map(bert_preprocessor, tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "electra_discriminator_back = keras_nlp.models.Backbone.from_preset(\"electra_small_discriminator_uncased_en\")\n",
    "\n",
    "electra_classifier = keras_nlp.models.BertClassifier(electra_discriminator_back, 3, preprocessor=None)\n",
    "\n",
    "classifier_history = electra_classifier.fit(train_set, epochs=5)\n",
    "training_losses = classifier_history.history[\"loss\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on test data for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(DATA_DIR + \"test.csv\")\n",
    "print(df_test.head())\n",
    "df_test[\"label\"] = [0] * len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            df_test[[\"hypothesis\", \"premise\"]].values,\n",
    "            df_test[\"label\"].values\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "print(len(testing_dataset))\n",
    "\n",
    "test_preprocessed = testing_dataset.map(split_labels, tf.data.AUTOTUNE).batch(1, drop_remainder=True).cache().prefetch(tf.data.AUTOTUNE)\n",
    "bert_test_set = (test_preprocessed.map(bert_preprocessor, tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = electra_classifier.predict(bert_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = tf.argmax(predictions, axis=1)\n",
    "predicted_classes_np = predicted_classes.numpy()\n",
    "print(predicted_classes_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df_test.id.copy().to_frame()\n",
    "submission[\"prediction\"] = predicted_classes_np\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
